# langchain_mcp_server.py - FIXED + Team Info
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import asyncio
import logging
from typing import List, Dict, Any, Optional
import uvicorn
import os
from datetime import datetime
import sys

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

# LangChain imports
from langchain.schema import Document
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain_community.vectorstores import FAISS

# MCP ì„œë²„
from server import MariaDBServer

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI(title="LangChain + MCP Vector Chatbot", version="3.1.0")

# ì „ì—­ ë³€ìˆ˜
mcp_server: Optional[MariaDBServer] = None
vector_service: Optional['VectorSearchService'] = None

# ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡
conversation_memories: Dict[str, List[Dict[str, str]]] = {}

class ChatRequest(BaseModel):
    user_query: str
    session_id: str = "default"
    use_vector_search: bool = True

class ChatResponse(BaseModel):
    success: bool
    answer: str
    search_method: str
    sources: List[Dict[str, Any]] = []
    error: Optional[str] = None

class HealthResponse(BaseModel):
    status: str
    message: str
    timestamp: str
    services: Dict[str, str]
    active_sessions: int
    vector_store_initialized: bool

# ==================== ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤ ====================
class VectorSearchService:
    """MCP + LangChain ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤"""
    
    def __init__(self, mcp_server: MariaDBServer):
        self.mcp_server = mcp_server
        self.embeddings = OpenAIEmbeddings()
        self.vector_store = None
        self.documents_cache = []
        
    async def initialize_vector_store(self):
        """MCPë¡œ DB ë°ì´í„° ê°€ì ¸ì™€ì„œ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"""
        try:
            logger.info("ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹œì‘...")
            
            # ğŸ”¥ ìˆ˜ì •: self.mcp_server.pool ì§ì ‘ ì‚¬ìš©
            pool = self.mcp_server.pool
            if not pool:
                raise Exception("DB ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            documents = []
            
            async with pool.acquire() as conn:
                async with conn.cursor() as cursor:
                    # ========== 1. ì•„ì´í…œ ë°ì´í„° ë¡œë“œ ==========
                    await cursor.execute("""
                        SELECT 
                            i.id,
                            i.rarity,
                            i.`two-hander`,
                            i.stackable,
                            GROUP_CONCAT(DISTINCT CASE WHEN n.lang = 'ko' THEN n.value END) as name_ko,
                            GROUP_CONCAT(DISTINCT CASE WHEN n.lang = 'en' THEN n.value END) as name_en,
                            GROUP_CONCAT(DISTINCT CASE WHEN d.lang = 'ko' THEN d.value END) as desc_ko,
                            GROUP_CONCAT(DISTINCT CASE WHEN d.lang = 'en' THEN d.value END) as desc_en
                        FROM items i
                        LEFT JOIN item_names n ON i.id = n.item_id
                        LEFT JOIN item_descriptions d ON i.id = d.item_id
                        GROUP BY i.id, i.rarity, i.`two-hander`, i.stackable
                    """)
                    items = await cursor.fetchall()
                    
                    # item_attributes ê°€ì ¸ì˜¤ê¸°
                    await cursor.execute("""
                        SELECT item_id, op, stat, value
                        FROM item_attributes
                    """)
                    attributes = await cursor.fetchall()
                    
                    # ========== 2. íŒ€ ì •ë³´ ë°ì´í„° ë¡œë“œ ==========
                    await cursor.execute("""
                        SELECT name, role, emoji
                        FROM team_members
                        ORDER BY id
                    """)
                    team_members = await cursor.fetchall()
            
            # ì•„ì´í…œë³„ ì†ì„± ë§¤í•‘
            item_attrs = {}
            for attr in attributes:
                item_id = attr[0]
                if item_id not in item_attrs:
                    item_attrs[item_id] = []
                item_attrs[item_id].append({
                    'op': attr[1],
                    'stat': attr[2],
                    'value': attr[3]
                })
            
            # ========== ì•„ì´í…œ Document ìƒì„± ==========
            for item in items:
                item_id = item[0]
                name_ko = item[4] or "ì´ë¦„ ì—†ìŒ"
                name_en = item[5] or "No name"
                desc_ko = item[6] or ""
                desc_en = item[7] or ""
                rarity = item[1]
                two_hander = item[2]
                stackable = item[3]
                
                # ì†ì„± ì •ë³´
                attrs = item_attrs.get(item_id, [])
                attrs_text = ", ".join([f"{a['stat']}: {a['op']} {a['value']}" for a in attrs])
                
                # ê²€ìƒ‰ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ êµ¬ì„±
                content = f"""
ì•„ì´í…œ ID: {item_id}
í•œê¸€ ì´ë¦„: {name_ko}
ì˜ë¬¸ ì´ë¦„: {name_en}
ë“±ê¸‰: {rarity}
ì–‘ì† ë¬´ê¸°: {'ì˜ˆ' if two_hander else 'ì•„ë‹ˆì˜¤'}
ì¤‘ì²© ê°€ëŠ¥: {'ì˜ˆ' if stackable else 'ì•„ë‹ˆì˜¤'}
ì„¤ëª…(í•œê¸€): {desc_ko}
ì„¤ëª…(ì˜ë¬¸): {desc_en}
ëŠ¥ë ¥ì¹˜: {attrs_text}
                """.strip()
                
                doc = Document(
                    page_content=content,
                    metadata={
                        "item_id": item_id,
                        "name_ko": name_ko,
                        "name_en": name_en,
                        "rarity": rarity,
                        "attributes": attrs,
                        "source": "items_table",
                        "type": "item"
                    }
                )
                documents.append(doc)
            
            # ========== íŒ€ ì •ë³´ Document ìƒì„± ==========
            if team_members:
                team_content = "ğŸ¤ ê°œë°œíŒ€ ì •ë³´\n\n"
                for member in team_members:
                    name = member[0]
                    role = member[1]
                    emoji = member[2] or ""
                    team_content += f"{emoji} {name}: {role}\n"
                
                team_doc = Document(
                    page_content=team_content,
                    metadata={
                        "source": "team_members",
                        "type": "team_info"
                    }
                )
                documents.append(team_doc)
                logger.info(f"íŒ€ ì •ë³´ ë¬¸ì„œ ì¶”ê°€: {len(team_members)}ëª…")
            
            self.documents_cache = documents
            
            # FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
            if documents:
                self.vector_store = FAISS.from_documents(
                    documents,
                    self.embeddings
                )
                logger.info(f"ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ (ì•„ì´í…œ + íŒ€ ì •ë³´)")
            else:
                logger.warning("ë¬¸ì„œê°€ ì—†ì–´ì„œ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.error(f"ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def search_similar(self, query: str, k: int = 5) -> List[Document]:
        """ì˜ë¯¸ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰"""
        if not self.vector_store:
            logger.warning("ë²¡í„° ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return []
        
        try:
            results = self.vector_store.similarity_search(query, k=k)
            logger.info(f"ë²¡í„° ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
            return results
        except Exception as e:
            logger.error(f"ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

# ==================== ì§ì ‘ SQL ê²€ìƒ‰ (Fallback) ====================
class DirectSQLSearcher:
    """ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•˜ëŠ” ì§ì ‘ SQL ê²€ìƒ‰"""
    
    def __init__(self, mcp_server: MariaDBServer):
        self.mcp_server = mcp_server
    
    async def search(self, query: str, k: int = 3) -> List[Document]:
        """ê°„ë‹¨í•œ LIKE ê²€ìƒ‰"""
        try:
            pool = self.mcp_server.pool
            documents = []
            
            # íŒ€ ì •ë³´ ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
            team_keywords = ['ê°œë°œì', 'íŒ€', 'ë©¤ë²„', 'êµ¬ì„±ì›', 'ëˆ„ê°€', 'ëˆ„êµ¬', 'ë§Œë“ ', 'ì œì‘']
            is_team_query = any(keyword in query for keyword in team_keywords)
            
            async with pool.acquire() as conn:
                async with conn.cursor() as cursor:
                    # íŒ€ ì •ë³´ ê²€ìƒ‰
                    if is_team_query:
                        await cursor.execute("""
                            SELECT name, role, emoji
                            FROM team_members
                            ORDER BY id
                        """)
                        team_results = await cursor.fetchall()
                        
                        if team_results:
                            team_content = "ğŸ¤ ê°œë°œíŒ€ ì •ë³´\n\n"
                            for member in team_results:
                                name = member[0]
                                role = member[1]
                                emoji = member[2] or ""
                                team_content += f"{emoji} {name}: {role}\n"
                            
                            doc = Document(
                                page_content=team_content,
                                metadata={
                                    "source": "team_members",
                                    "type": "team_info"
                                }
                            )
                            documents.append(doc)
                    
                    # ì•„ì´í…œ ê²€ìƒ‰
                    await cursor.execute("""
                        SELECT DISTINCT i.id, n.value, i.rarity
                        FROM items i
                        JOIN item_names n ON i.id = n.item_id
                        WHERE n.value LIKE %s AND n.lang = 'ko'
                        LIMIT %s
                    """, (f"%{query}%", k))
                    
                    results = await cursor.fetchall()
                    
                    for row in results:
                        content = f"ì•„ì´í…œ: {row[1]} (ID: {row[0]}, ë“±ê¸‰: {row[2]})"
                        doc = Document(
                            page_content=content,
                            metadata={
                                "item_id": row[0],
                                "name": row[1],
                                "rarity": row[2],
                                "source": "direct_sql",
                                "type": "item"
                            }
                        )
                        documents.append(doc)
            
            return documents
        except Exception as e:
            logger.error(f"ì§ì ‘ SQL ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

# ==================== ì±—ë´‡ ì„œë¹„ìŠ¤ ====================
class SmartChatService:
    """í†µí•© ì±—ë´‡ ì„œë¹„ìŠ¤"""
    
    def __init__(self, mcp_server: MariaDBServer, vector_service: VectorSearchService):
        self.mcp_server = mcp_server
        self.vector_service = vector_service
        self.sql_searcher = DirectSQLSearcher(mcp_server)
        
        self.chat_model = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.7
        )
        
        self.prompt_template = PromptTemplate.from_template("""
ë‹¹ì‹ ì€ ê²Œì„ ì•„ì´í…œ ì •ë³´ì™€ ê°œë°œíŒ€ ì •ë³´ë¥¼ ì•ˆë‚´í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

[ëŒ€í™” ê¸°ë¡]
{history}

[ê²€ìƒ‰ëœ ê´€ë ¨ ì •ë³´]
{context}

[ì‚¬ìš©ì ì§ˆë¬¸]
{input}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
- ì•„ì´í…œ ì •ë³´ ì§ˆë¬¸ì´ë©´ ì•„ì´í…œ ì´ë¦„, ë“±ê¸‰, ëŠ¥ë ¥ì¹˜ ë“±ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.
- ê°œë°œíŒ€/ê°œë°œì ì •ë³´ ì§ˆë¬¸ì´ë©´ íŒ€ êµ¬ì„±ì›ê³¼ ì—­í• ì„ ì•ˆë‚´í•´ì£¼ì„¸ìš”.
- ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ë³´ê¸° ì¢‹ê²Œ ì‘ì„±í•˜ì„¸ìš”.

ë‹µë³€:
""")
    
    async def generate_response(
        self,
        user_query: str,
        session_id: str = "default",
        use_vector: bool = True
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±"""
        try:
            # 1. ê²€ìƒ‰ ë°©ë²• ì„ íƒ
            if use_vector and self.vector_service.vector_store:
                search_method = "vector"
                relevant_docs = await self.vector_service.search_similar(user_query, k=5)
            else:
                search_method = "direct_sql"
                relevant_docs = await self.sql_searcher.search(user_query, k=3)
            
            # 2. ê²€ìƒ‰ ê²°ê³¼ ì—†ìœ¼ë©´ ì‹¤íŒ¨
            if not relevant_docs:
                return {
                    "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”!",
                    "search_method": search_method,
                    "sources": []
                }
            
            # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = "\n\n---\n\n".join([doc.page_content for doc in relevant_docs[:3]])
            
            # 4. ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
            history = ""
            if session_id in conversation_memories:
                recent = conversation_memories[session_id][-4:]
                history = "\n".join([f"{msg['role']}: {msg['content']}" for msg in recent])
            
            # 5. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.prompt_template.format(
                history=history,
                context=context,
                input=user_query
            )
            
            # 6. AI ì‘ë‹µ ìƒì„±
            response = await self.chat_model.ainvoke(prompt)
            answer = response.content
            
            # 7. ëŒ€í™” ê¸°ë¡ ì €ì¥
            if session_id not in conversation_memories:
                conversation_memories[session_id] = []
            
            conversation_memories[session_id].extend([
                {"role": "user", "content": user_query},
                {"role": "assistant", "content": answer}
            ])
            
            # ìµœê·¼ 10í„´ë§Œ ìœ ì§€
            if len(conversation_memories[session_id]) > 20:
                conversation_memories[session_id] = conversation_memories[session_id][-20:]
            
            # 8. ì†ŒìŠ¤ ì •ë³´ êµ¬ì„±
            sources = []
            for doc in relevant_docs[:3]:
                if doc.metadata.get("type") == "team_info":
                    sources.append({
                        "type": "team_info",
                        "source": "team_members"
                    })
                else:
                    sources.append({
                        "item_id": doc.metadata.get("item_id"),
                        "name": doc.metadata.get("name_ko"),
                        "rarity": doc.metadata.get("rarity"),
                        "source": doc.metadata.get("source"),
                        "type": "item"
                    })
            
            return {
                "answer": answer,
                "search_method": search_method,
                "sources": sources
            }
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "search_method": "error",
                "sources": []
            }

# ==================== FastAPI ì´ë²¤íŠ¸ ====================
chat_service: Optional[SmartChatService] = None

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘"""
    global mcp_server, vector_service, chat_service
    
    try:
        logger.info("=" * 60)
        logger.info("ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ì±—ë´‡ ì„œë²„ ì‹œì‘")
        logger.info("=" * 60)
        
        # 1. MCP ì„œë²„ ì´ˆê¸°í™”
        logger.info("MCP ì„œë²„ ì´ˆê¸°í™”...")
        mcp_server = MariaDBServer()
        await mcp_server.initialize_pool()
        mcp_server.register_tools()
        logger.info("MCP ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 2. ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        logger.info("ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”...")
        vector_service = VectorSearchService(mcp_server)
        await vector_service.initialize_vector_store()
        logger.info("ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 3. ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        logger.info("ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”...")
        chat_service = SmartChatService(mcp_server, vector_service)
        logger.info("ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 4. OpenAI API í‚¤ í™•ì¸
        if not os.getenv('OPENAI_API_KEY'):
            logger.warning("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        else:
            logger.info("OpenAI API í‚¤ í™•ì¸ë¨")
        
        logger.info("=" * 60)
        logger.info("ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
        logger.info("ì„œë²„: http://0.0.0.0:3003")
        logger.info("Chat: POST http://localhost:3003/chat")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """ì„œë²„ ì¢…ë£Œ"""
    global mcp_server
    if mcp_server:
        await mcp_server.close_pool()
        logger.info("ì„œë²„ ì¢…ë£Œ ì™„ë£Œ")

# ==================== API ì—”ë“œí¬ì¸íŠ¸ ====================

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    openai_status = "UP" if os.getenv('OPENAI_API_KEY') else "DOWN"
    mcp_status = "UP" if mcp_server else "DOWN"
    vector_status = "UP" if (vector_service and vector_service.vector_store) else "DOWN"
    chat_status = "UP" if chat_service else "DOWN"
    
    overall = "UP" if all([
        openai_status == "UP",
        mcp_status == "UP",
        vector_status == "UP",
        chat_status == "UP"
    ]) else "DEGRADED"
    
    return HealthResponse(
        status=overall,
        message="Vector Search Chatbot is running",
        timestamp=datetime.now().isoformat(),
        services={
            "openai": openai_status,
            "mcp_server": mcp_status,
            "vector_store": vector_status,
            "chat_service": chat_status
        },
        active_sessions=len(conversation_memories),
        vector_store_initialized=(vector_service and vector_service.vector_store is not None)
    )

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸"""
    if not chat_service:
        raise HTTPException(status_code=500, detail="ì±—ë´‡ ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        logger.info(f"ì§ˆë¬¸ (ì„¸ì…˜: {request.session_id}): {request.user_query}")
        
        result = await chat_service.generate_response(
            user_query=request.user_query,
            session_id=request.session_id,
            use_vector=request.use_vector_search
        )
        
        logger.info(f"ì‘ë‹µ ì™„ë£Œ (ë°©ë²•: {result['search_method']})")
        
        return ChatResponse(
            success=True,
            answer=result["answer"],
            search_method=result["search_method"],
            sources=result.get("sources", [])
        )
        
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜: {e}")
        return ChatResponse(
            success=False,
            answer="ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            search_method="error",
            error=str(e)
        )

@app.post("/vector/rebuild")
async def rebuild_vector_store():
    """ë²¡í„° ìŠ¤í† ì–´ ì¬êµ¬ì¶•"""
    if not vector_service:
        raise HTTPException(status_code=500, detail="ë²¡í„° ì„œë¹„ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    try:
        await vector_service.initialize_vector_store()
        return {"message": "ë²¡í„° ìŠ¤í† ì–´ê°€ ì¬êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤", "document_count": len(vector_service.documents_cache)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¬êµ¬ì¶• ì‹¤íŒ¨: {e}")

@app.get("/sessions")
async def list_sessions():
    """ì„¸ì…˜ ëª©ë¡"""
    return {
        "total_sessions": len(conversation_memories),
        "sessions": list(conversation_memories.keys())
    }

@app.delete("/chat/{session_id}")
async def clear_session(session_id: str):
    """ì„¸ì…˜ ì‚­ì œ"""
    if session_id in conversation_memories:
        del conversation_memories[session_id]
        return {"message": f"ì„¸ì…˜ {session_id} ì‚­ì œë¨"}
    return {"message": "ì„¸ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"}

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=3003,
        reload=False,
        log_level="info"
    )